# AI Smalltalk Agents (AGENTS.md)

本プロジェクトは、OpenAI の gpt‑realtime API を用いた音声入力/出力による雑談ツールです。マイクから話しかけると、その内容がチャット形式で画面に表示され、アシスタントの音声応答がスピーカーから再生されます。人物設定（ペルソナ）を切り替えて会話スタイルを調整できます。

注意: 本ツールはローカル実行のみを想定しています（公開サービスとして運用しません）。

## 目的
- 雑談や読み上げをリアルタイムに行う対話体験を提供する。
- ペルソナを差し替えるだけで会話の性格や口調を簡単に変更できる。
- 会話履歴をチャット UI で可視化し、後から参照できるようにする。

## 主な機能
- ペルソナ設定（人物設定）の切替・管理
- 話した内容と応答をチャット形式で表示（タイムスタンプ付き）
- gpt‑realtime API を利用した低遅延の音声入出力（双方向ストリーミング）

---

## クイックスタート
以下はローカル実行の最小手順です（Node.js 18+ 推奨）。ワンコマンドと個別起動のどちらでも使えます。

1) 環境準備
- 必要: マイク・スピーカー、最新ブラウザ
- API キー: すでに `.env` に設定済みであれば OK（推奨は `server/.env`）。

2) ペルソナの選択
- `personas/` ディレクトリに JSON もしくは YAML でペルソナを配置します（例: `personas/friendly_ja.json`）。
- 起動時に `PERSONA` 環境変数やアプリ内メニューからペルソナを選択できるようにします。

3) 依存インストール（ワークスペース）
- ルートで一度だけ依存を入れます: `npm install`

4) 起動
- 方式A（推奨・ワンコマンド）: ルートで `npm run dev`
  - サーバ: http://localhost:8787
  - フロント: http://localhost:5173
- 方式B（個別起動）:
  - サーバ: `cd server && npm install && npm run dev`
  - フロント: `cd web && npm install && npm run dev`
  - ブラウザで `http://localhost:5173` を開く
- 初回起動時はマイク/スピーカー権限を OS / ブラウザで許可してください。

5) 接続と会話（PTT）
- 画面上部の「接続」をクリック → ステータスが「接続完了」になればOK
- 「押して話す（PTT）」を押している間だけ録音／離すと送信確定→応答が音声で再生
- ペルソナはセレクトボックスで切替（以降の応答に反映）

補足: ルート直下に `.env` を置いた場合は `server/.env` にコピーしてください（`dotenv` の読込はサーバ側で行います）。

---

## システム構成（ローカル）
- フロント（Vite + TypeScript）: マイク取得、PTT、チャットUI、WebRTCでRealtime接続
- サーバ（Express）: `/session` でエフェメラルセッション発行、`/personas` でペルソナ配布
- OpenAI: gpt‑realtime との双方向ストリーミング（WebRTC）

---

## よく使うエンドポイント（ローカル）
- `GET /health` : ヘルスチェック `{ ok: true }`
- `POST /session` : gpt‑realtime のエフェメラルセッション作成（サーバ内で API キーを使用）
- `GET /personas` / `GET /personas/:id` : ペルソナ一覧・詳細（`personas/*.json`）
- フロントからは `/api/*` → `http://localhost:8787/*` へプロキシ（Vite 設定）

4) 会話
- マイクに向かって話しかけると、ステータスに「録音中」などが表示され、
  発話がチャット欄にユーザーのメッセージとして記録されます。
- 応答は音声で再生され、同時にアシスタントのメッセージとして表示されます。

---

## ペルソナ（人物設定）
ペルソナは、アシスタントの「性格・口調・話し方・専門性」を規定します。以下は JSON 例です。

```json
{
  "id": "friendly_ja",
  "displayName": "フレンドリー日本語",
  "language": "ja",
  "system": "あなたはフレンドリーな会話相手です。短く、親しみやすい口調で、相槌を打ちながら会話してください。専門用語は避け、分かりやすく説明します。",
  "style": {
    "voice": "alloy",
    "speakingRate": 1.0,
    "pitch": 0
  },
  "guidelines": {
    "topics": ["日常", "雑談", "趣味"],
    "avoid": ["個人情報の深掘り", "医療・法律の確約"]
  },
  "fallbackLanguage": "ja"
}
```

- `system`: モデルに与える初期コンテキスト（振る舞いの要約・口調）。
- `style`: 音声の種類や話速など（利用可能な音声名はモデル/環境に依存）。
- `guidelines`: 取り上げる/避ける話題などの方針。
- `fallbackLanguage`: 聞き取りに失敗した際の返答言語。

複数のペルソナを `personas/` に置き、起動時/実行時に切り替えられる UI または CLI オプションを備えることを推奨します。

---

## チャット表示（会話ログ）
- 各メッセージは以下の情報を持ちます。
  - `role`: `user` | `assistant` | `system`
  - `content`: 文字起こしまたは生成テキスト
  - `timestamp`: ISO 文字列（例: `2025-08-30T09:00:00Z`）
  - `personaId`（任意）: その発話時に有効だったペルソナ
- 表示例（擬似）:

```
[09:01:12] user: おはよう！
[09:01:13] assistant (friendly_ja): おはようございます！今日はどう過ごしますか？
```

- 音声→テキスト変換（STT）や、モデル側の発話をそのままテキスト化して記録します。
- UI では最新メッセージが見やすいよう自動スクロール、発話中インジケータ、
  再生/一時停止の操作を備えると便利です。

---

## gpt‑realtime 連携の考え方
- セッション: モデルと双方向ストリーミングのセッションを確立し、音声フレーム/テキストを送受信します。
- 入力: マイク音声（VAD で区切り）と任意のテキスト指示（システム/ユーザー）を送信します。
- 出力: モデルからの音声ストリームを受信・再生し、同時にテキストもログへ反映します。
- モデル: `REALTIME_MODEL` で指定（例: `gpt-realtime` 系）。
- 音声: 取り回しやすいサンプリングレート（例: 16kHz 以上）とエンコード形式を選択。環境に応じて最適化してください。

実装パターン（例）
- ブラウザ/Web アプリ: サーバー側で短期のエフェメラルトークンを発行し、クライアントは WebRTC/WS で接続。
- デスクトップ/CLI: クライアントから直接セッションを張り、音声 I/O を自前で制御。

セキュリティ
- API キーはクライアント（ブラウザ）に直接埋め込まないでください。サーバー側で保護し、
  必要に応じて短期トークンを発行して接続する方式を推奨します。

---

## 環境変数（例）
- `OPENAI_API_KEY`: OpenAI API キー
- `REALTIME_MODEL`: 利用する realtime 系モデル名（未設定時は既定のモデル）
- `VOICE_NAME`: 音声出力に用いる音声の識別子
- `PERSONA`: 既定で読み込むペルソナファイル名（例: `friendly_ja.json`）
- `LOG_TRANSCRIPTS`: `true` にすると文字起こしを永続化（デフォルトは無効）

※ 実際に使用するキー名は実装に合わせて変更してください。`.env.example` を用意すると利用者が迷いません。

---

## トラブルシューティング
- 音が出ない: 出力デバイスの選択、音量、ミュート状態、アプリの再生許可を確認。
- マイクが取れない: OS/ブラウザのマイク権限、排他制御中のアプリ有無を確認。
- 途切れる/遅い: サンプリングレートやフレームサイズ、VAD 閾値、ネットワーク品質を見直し。
- 日本語が不自然: ペルソナ `system` の指示を具体化、`fallbackLanguage` を `ja` に設定。
- API 鍵エラー: `OPENAI_API_KEY` とトークン発行フロー（ブラウザ利用時）を再確認。

---

## 最低限の確認手順
- サーバ: `curl http://localhost:8787/health` → `{ ok: true }`
- フロント: 画面の「接続」→「押して話す（PTT）」→ ボタンを離すと応答が音声で再生
- コンソール: ブラウザ/サーバのログにエラーが出ていないことを確認

---

## 開発メモ
- ペルソナは小さく反復的に調整するのが効果的です。まずは口調・長さ・話題範囲の 3 点に的を絞ると安定します。
- ログは個人情報を含む可能性があるため、既定では保存しない（`LOG_TRANSCRIPTS=false`）設計を推奨します。
- UI/UX: 発話中の視覚フィードバック、応答のキャンセル、聞き返し（"すみません、今なんと？"）などが会話体験を向上します。

---

## 参考テンプレート（擬似コード）
以下は実装時の流れを掴むための擬似コードです。実際の API/SDK の呼び出しは採用スタックに合わせて置き換えてください。

```ts
// 1) セッション確立
const session = await createRealtimeSession({
  apiKey: process.env.OPENAI_API_KEY,
  model: process.env.REALTIME_MODEL || 'gpt-realtime',
  voice: process.env.VOICE_NAME || 'alloy'
});

// 2) ペルソナ適用
const persona = loadPersona(process.env.PERSONA || 'friendly_ja.json');
session.setSystemPrompt(persona.system);

// 3) 音声入力 → モデルへ送信
mic.on('audioFrame', (pcm) => {
  if (!vad.isSpeech(pcm)) return;
  session.sendAudio(pcm); // 双方向ストリームへプッシュ
});

// 4) 応答の受信（音声＋テキスト）
session.on('audio', (chunk) => speaker.play(chunk));
session.on('text', (message) => ui.append({ role: 'assistant', content: message }));

// 5) チャット UI 側
ui.onUserSpeak((text) => session.sendText(text));
```

---

このドキュメントは、実装の方向性と運用ガイドをまとめたものです。実際のコード・起動方法・設定キーはプロジェクトの実装に合わせて調整してください。
